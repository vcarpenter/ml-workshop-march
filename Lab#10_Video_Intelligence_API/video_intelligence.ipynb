{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Intelligence API\n",
    "Google Cloud Video Intelligence makes videos searchable, and discoverable, by extracting metadata with an easy to use REST API. You can now search every moment of every video file in your catalog. It quickly annotates videos stored in Google Cloud Storage, and helps you identify key entities (nouns) within your video; and when they occur within the video. Separate signal from noise, by retrieving relevant information within the entire video, shot-by-shot, -or per frame.\n",
    "<br><br><br>\n",
    "Please [set up a Google Cloud Video Intelligence API project in the Google Cloud Platform Console](https://cloud.google.com/video-intelligence/docs/before-you-begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import videointelligence\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## Gather Insight from 20,000 Labels\n",
    "Cloud Video Intelligence allows developers to extract actionable insights from video files without requiring any machine learning or computer vision knowledge. From our massive library of 20,000 labels, it automatically analyzes video content to identify what entities are in your video content and when they appear. Cloud Video Intelligence improves over time as new concepts are introduced and accuracy is improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def analyze_labels(path):\n",
    "    \"\"\" Detects labels given a GCS path. \"\"\"\n",
    "    video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "    features = [videointelligence.enums.Feature.LABEL_DETECTION]\n",
    "    operation = video_client.annotate_video(path, features=features)\n",
    "    print('\\nProcessing video for label annotations:')\n",
    "\n",
    "    result = operation.result(timeout=90)\n",
    "    print('\\nFinished processing.')\n",
    "\n",
    "    segment_labels = result.annotation_results[0].segment_label_annotations\n",
    "    for i, segment_label in enumerate(segment_labels):\n",
    "        print('Video label description: {}'.format(\n",
    "            segment_label.entity.description))\n",
    "        for category_entity in segment_label.category_entities:\n",
    "            print('\\tLabel category description: {}'.format(\n",
    "                category_entity.description))\n",
    "\n",
    "        for i, segment in enumerate(segment_label.segments):\n",
    "            start_time = (segment.segment.start_time_offset.seconds +\n",
    "                          segment.segment.start_time_offset.nanos / 1e9)\n",
    "            end_time = (segment.segment.end_time_offset.seconds +\n",
    "                        segment.segment.end_time_offset.nanos / 1e9)\n",
    "            positions = '{}s to {}s'.format(start_time, end_time)\n",
    "            confidence = segment.confidence\n",
    "            print('\\tSegment {}: {}'.format(i, positions))\n",
    "            print('\\tConfidence: {}'.format(confidence))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "analyze_labels('gs://cloud-ml-sandbox/video/chicago.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Signals from Noise\n",
    "You can identify the presence of a signal buried in noise, by using shot detection to distinguish scene changes within a video and discern only relevant entities at the video, shot or frame level (e.g. Identify “dog” within a new scene)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_shots(path):\n",
    "    \"\"\" Detects camera shot changes. \"\"\"\n",
    "    video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "    features = [videointelligence.enums.Feature.SHOT_CHANGE_DETECTION]\n",
    "    operation = video_client.annotate_video(path, features=features)\n",
    "    print('\\nProcessing video for shot change annotations:')\n",
    "\n",
    "    result = operation.result(timeout=90)\n",
    "    print('\\nFinished processing.')\n",
    "\n",
    "    for i, shot in enumerate(result.annotation_results[0].shot_annotations):\n",
    "        start_time = (shot.start_time_offset.seconds +\n",
    "                      shot.start_time_offset.nanos / 1e9)\n",
    "        end_time = (shot.end_time_offset.seconds +\n",
    "                    shot.end_time_offset.nanos / 1e9)\n",
    "        print('\\tShot {}: {} to {}'.format(i, start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing video for shot change annotations:\n",
      "\n",
      "Finished processing.\n",
      "\tShot 0: 0.0 to 5.166666\n",
      "\tShot 1: 5.233333 to 10.066666\n",
      "\tShot 2: 10.1 to 28.133333\n",
      "\tShot 3: 28.166666 to 42.766666\n"
     ]
    }
   ],
   "source": [
    "analyze_shots('gs://demomaker/gbikes_dinosaur.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# Bonus Lab: Build Video Search Catalog\n",
    "Codebase and instructions can be found on [this github repo](https://github.com/sararob/video-intelligence-demo)\n",
    "If you want to see a [demo on youtube](https://www.youtube.com/watch?v=mDAoLO4G4CQ)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
