{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Text Analysis of News\n",
    "<font color=\"red\"><b>This is NOT an Official Google Product and is only for education!!!</b></font>\n",
    "<br><br>\n",
    "Google Cloud Natural Language reveals the structure and meaning of text by offering powerful machine learning models in an easy to use REST API. You can use it to extract information about people, places, events and much more, mentioned in text documents, news articles or blog posts. You can use it to understand sentiment about your product on social media or parse intent from customer conversations happening in a call center or a messaging app.\n",
    "\n",
    "In this example, we will use [Natural Language API](https://cloud.google.com/natural-language/) to do complete text analysis of News Headlines & Abstracts from New York Times (Data is gathered from [Public API of New York Times](https://developer.nytimes.com/)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://fox_workshop/news.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "df = pd.read_csv(\"news.csv\")\n",
    "df.drop_duplicates(subset=['title', 'abstract','section'], keep=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br><br>\n",
    "## Analyzing News Headlines for Entities\n",
    "Entity Analysis inspects the given text for known entities (proper nouns such as public figures, landmarks, etc.), and returns information about those entities. Entity analysis is performed with the analyzeEntities method. For information on which languages are supported by the Natural Language API, see [Language Support](https://cloud.google.com/natural-language/docs/languages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def analyze_title(text):\n",
    "    \"\"\"Detects entities in the text.\"\"\"\n",
    "    client = language.LanguageServiceClient()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "    # Instantiates a plain text document.\n",
    "    document = types.Document(\n",
    "        content=text,\n",
    "        type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    # Detects entities in the document. You can also analyze HTML with:\n",
    "    #   document.type == enums.Document.Type.HTML\n",
    "    entities = client.analyze_entities(document).entities\n",
    "\n",
    "    # entity types from enums.Entity.Type\n",
    "    entity_type = ('UNKNOWN', 'PERSON', 'LOCATION', 'ORGANIZATION',\n",
    "                   'EVENT', 'WORK_OF_ART', 'CONSUMER_GOOD', 'OTHER')\n",
    "    entities_people = []\n",
    "    entities_locations = []\n",
    "    entities_organizations = []\n",
    "    for entity in entities:\n",
    "        if entity_type[entity.type] == 'PERSON' and  entity.metadata.get('wikipedia_url', '-') != '-':\n",
    "          entities_people.append(entity.name)\n",
    "        if entity_type[entity.type] == 'LOCATION':\n",
    "          entities_locations.append(entity.name)\n",
    "        if entity_type[entity.type] == 'ORGANIZATION':\n",
    "          entities_organizations.append(entity.name)\n",
    "    return entities_people,entities_locations,entities_organizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br><br>\n",
    "## Sentiment Analysis for News Headlines\n",
    "\n",
    "Sentiment Analysis inspects the given text and identifies the prevailing emotional opinion within the text, especially to determine a writer's attitude as positive, negative, or neutral. Sentiment analysis is performed through the analyzeSentiment method\n",
    "<br><br><br>\n",
    "### Understanding the response\n",
    "The response has two elements:\n",
    "* score of the sentiment ranges between -1.0 (negative) and 1.0 (positive) and corresponds to the overall emotional leaning of the text.\n",
    "* magnitude indicates the overall strength of emotion (both positive and negative) within the given text, between 0.0 and +inf. \n",
    "\n",
    "Unlike score, magnitude is not normalized; each expression of emotion within the text (both positive and negative) contributes to the text's magnitude (so longer text blocks may have greater magnitudes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sentiment_text(text):\n",
    "    \"\"\"Detects sentiment in the text.\"\"\"\n",
    "    client = language.LanguageServiceClient()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "    document = types.Document(\n",
    "        content=text,\n",
    "        type=enums.Document.Type.PLAIN_TEXT)\n",
    "    sentiment = client.analyze_sentiment(document).document_sentiment\n",
    "    return sentiment.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br><br>\n",
    "### Now lets Analyze Entities in our News Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Google Cloud Libraries for NLP\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "import six\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  individuals,locations,organizations = analyze_title(row['title'])\n",
    "  df.loc[index,'individuals'] = ', '.join(individuals)\n",
    "  df.loc[index,'locations'] = ', '.join(locations)\n",
    "  df.loc[index,'organizations'] = ', '.join(organizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df[df['individuals'].str.contains('Trump') &  df['sentiment_score_title'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Now lets Analyze Sentiment in our News Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "  sentiment_score_title = sentiment_text(row['title'])\n",
    "  df.loc[index,'sentiment_score_title'] = float(sentiment_score_title)\n",
    "  time.sleep(.300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## BIGQUERY\n",
    "\n",
    "BigQuery is Google's serverless, highly scalable, low cost enterprise data warehouse designed to make all your data analysts productive. Because there is no infrastructure to manage, you can focus on analyzing data to find meaningful insights using familiar SQL and you don't need a database administrator. BigQuery enables you to analyze all your data by creating a logical data warehouse over managed, columnar storage as well as data from object storage, and spreadsheets. BigQuery makes it easy to securely share insights within your organization and beyond as datasets, queries, spreadsheets and reports. BigQuery allows organizations to capture and analyze data in real-time using its powerful streaming ingestion capability so that your insights are always current.. \n",
    "<br>\n",
    "* Learn more [here](https://cloud.google.com/bigquery/)\n",
    "* Quick Video is [Here](https://www.youtube.com/watch?time_continue=4&v=eyBK9nj-7AA) In case you dont like reading:) \n",
    "\n",
    "<br>\n",
    "Below we will insert our DataFrame into BigQuery for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "\n",
    "bigquery_dataset_name = 'news_feed_0622'\n",
    "bigquery_table_name = 'news_entity_sent_headlines'\n",
    "\n",
    "# Define BigQuery dataset and table\n",
    "dataset = bq.Dataset(bigquery_dataset_name)\n",
    "table = bq.Table(bigquery_dataset_name + '.' + bigquery_table_name)\n",
    "\n",
    "# Create BigQuery dataset\n",
    "if not dataset.exists():\n",
    "  print (\"Dataset Not Found in BigQuery!! Creating One!!\")\n",
    "  dataset.create()\n",
    "\n",
    "# Create or overwrite the existing table if it exists\n",
    "table_schema = bq.Schema.from_data(df)\n",
    "if not table.exists():\n",
    "  print (\"Table Not Found in BigQuery!! Creating One!!\")\n",
    "  table.create(schema = table_schema, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert \n",
    "Inserting the dataframe we created into BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table.insert(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Plotting Queries\n",
    "You can run SQL Queries from BigQuery & plot the results. More examples can be found [here](https://cloud.google.com/bigquery/docs/visualize-datalab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bq query --name section_sentiment_avg \n",
    "SELECT section, avg(sentiment_score_title) AS sentiment\n",
    "## ENTER YOUR OWN Project ID, DataSet Name & Table Name Below \n",
    "## FROM `<PROJECT ID>.<DATASET NAME>.<TABLE NAME>`\n",
    "FROM `ml-workshop-198917.news_feed_0622.news_entity_sent_headlines`\n",
    "WHERE sentiment_score_title != 0\n",
    "GROUP BY section\n",
    "ORDER BY sentiment DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%chart columns --data section_sentiment_avg --fields section,sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bq query\n",
    "SELECT title, sentiment_score_title AS sentiment\n",
    "FROM `ml-workshop-198917.news_feed_0622.news_entity_sent_headlines`\n",
    "WHERE sentiment_score_title != 0 and individuals LIKE \"%Trump%\"\n",
    "ORDER BY sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bq query\n",
    "SELECT title, sentiment_score_title AS sentiment\n",
    "FROM `ml-workshop-198917.news_feed_0622.news_entity_sent_headlines`\n",
    "WHERE sentiment_score_title != 0 and organizations LIKE \"%Netflix%\"\n",
    "ORDER BY sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## BigQuery to DataFrame\n",
    "Below is an example of how you can convert BigQuery output to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "SELECT\n",
    "  title,\n",
    "  abstract,\n",
    "  section\n",
    "FROM `ml-workshop-198917.news_feed_0622.news_entity_sent_headlines`\n",
    "\"\"\"\n",
    "\n",
    "import google.datalab.bigquery as bq\n",
    "df_news = bq.Query(query).execute().result().to_dataframe()\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>\n",
    "# Bonus Lab - Analyze realtime tweets with NLP API & BigQuery\n",
    "\n",
    "Explore this [tutorial](https://github.com/vcarpenter/google_cloud_machine_learning_api#natural-language-api-bigquery-demo) on streaming real time tweets from twitter to NLP API and saving them in BigQuery for deep analysis. Codebase can be found [here](https://github.com/vcarpenter/google_cloud_machine_learning_api/tree/master/natural-language)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
