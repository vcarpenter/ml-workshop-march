{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classify Images via Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will build a simple model in Cloud ML using a small set of labeled flower images. This dataset has been selected for ease of explanation only; We've successfully used the same implementation for several proprietary datasets covering cases like interior-design classification (e.g., carpet vs. hardwood floor) and animated-character classification. The code can be found https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/flowers and can easily be adapted to run on different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess Data\n",
    "We start with a set of labeled images in a Google Cloud Storage bucket and preprocess them to extract the image features from the bottleneck layer (typically the penultimate layer) of the Inception network. Although processing images in this manner can be reasonably expensive, each image can be processed independently and in parallel, making this task a great candidate for Cloud Dataflow.\n",
    "\n",
    "We process each image to produce its feature representation (also known as an embedding) in the form of a k-dimensional vector of floats (in our case 2,048 dimensions). The preprocessing includes converting the image format, resizing images, and running the converted image through a pre-trained model to get the embeddings. Final output will be written in directory specified by --output_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "GCS_BUCKET = 'gs://ml-workshop-transfer-learning' #CHANGE THIS TO YOUR BUCKET\n",
    "PROJECT = 'march-ml-workshop' #CHANGE THIS TO YOUR PROJECT ID\n",
    "REGION = 'us-central1' #OPTIONALLY CHANGE THIS\n",
    "TIME = str(int(time.time()))\n",
    "GCS_PATH= GCS_BUCKET + \"/\" + TIME\n",
    "\n",
    "import os\n",
    "os.environ['GCS_BUCKET'] = GCS_BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['GCS_PATH'] = GCS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Updates are available for some Cloud SDK components.  To install them,\n",
      "please run:\n",
      "  $ gcloud components update\n",
      "\n",
      "Creating gs://ml-workshop-transfer-learning/...\n",
      "Copying gs://cloud-ml-data/img/flower_photos/train_set.csv [Content-Type=text/csv]...\n",
      "/ [1 files][260.0 KiB/260.0 KiB]                                                \n",
      "Operation completed over 1 objects/260.0 KiB.                                    \n",
      "Copying gs://cloud-ml-data/img/flower_photos/eval_set.csv [Content-Type=text/csv]...\n",
      "/ [1 files][ 29.3 KiB/ 29.3 KiB]                                                \n",
      "Operation completed over 1 objects/29.3 KiB.                                     \n",
      "Copying gs://cloud-ml-data/img/flower_photos/dict.txt [Content-Type=text/plain]...\n",
      "/ [1 files][   40.0 B/   40.0 B]                                                \n",
      "Operation completed over 1 objects/40.0 B.                                       \n"
     ]
    }
   ],
   "source": [
    "!gsutil mb $GCS_BUCKET\n",
    "!gsutil cp -r gs://cloud-ml-data/img/flower_photos/train_set.csv $GCS_BUCKET/img/flower_photos/\n",
    "!gsutil cp -r gs://cloud-ml-data/img/flower_photos/eval_set.csv $GCS_BUCKET/img/flower_photos/\n",
    "!gsutil cp -r gs://cloud-ml-data/img/flower_photos/dict.txt $GCS_BUCKET/img/flower_photos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-data/img/flower_photos/sunflowers/14646281372_5f13794b47.jpg,sunflowers\n",
      "daisy\n",
      "dandelion\n",
      "roses\n",
      "sunflowers\n",
      "tulips\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat -r 0-85  $GCS_BUCKET/img/flower_photos/eval_set.csv\n",
    "!gsutil cat $GCS_BUCKET/img/flower_photos/dict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n",
      "370\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat gs://cloud-ml-data/img/flower_photos/train_set.csv | wc -l\n",
    "!gsutil cat gs://cloud-ml-data/img/flower_photos/eval_set.csv | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Machine Learning Pipeline \n",
    "We are setting up following pipeline \n",
    "![Machine Learning Pipeline](pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "# SKIP THIS STEP & Go to Next \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "### Preprocessing \n",
    "(Optional: This take about 50 minutes to run in DataFlow over 20 single core VMs)\n",
    "<br><br>\n",
    "We start with a set of labeled images in a Google Cloud Storage bucket and preprocess them to extract the image features from the bottleneck layer (typically the penultimate layer) of the Inception network. Although processing images in this manner can be reasonably expensive, each image can be processed independently and in parallel, making this task a great candidate for Cloud Dataflow.\n",
    "\n",
    "We process each image to produce its feature representation (also known as an embedding) in the form of a k-dimensional vector of floats (in our case 2,048 dimensions). The preprocessing includes converting the image format, resizing images, and running the converted image through a pre-trained model to get the embeddings. Final output will be written in directory specified by --output_path.\n",
    "\n",
    "<br>\n",
    "(uri, label_ids, image_bytes) -> (tensorflow.Example).\n",
    "\n",
    "  Output proto contains 'label', 'image_uri' and 'embedding'.\n",
    "  The 'embedding' is calculated by feeding image into input layer of image\n",
    "  neural network and reading output of the bottleneck layer of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!python trainer/preprocess.py \\\n",
    "  --input_dict $GCS_BUCKET/img/flower_photos/dict.txt \\\n",
    "  --input_path $GCS_BUCKET/img/flower_photos/eval_set.csv \\\n",
    "  --output_path $GCS_PATH/preproc/eval \\\n",
    "  --num_workers 10 \\\n",
    "  --cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/oauth2client/contrib/gce.py:99: UserWarning: You have requested explicit scopes to be used with a GCE service account.\n",
      "Using this argument will have no effect on the actual scopes for tokens\n",
      "requested. These scopes are set at VM instance creation time and\n",
      "can't be overridden in the request.\n",
      "\n",
      "  warnings.warn(_SCOPES_WARNING)\n",
      "/usr/local/lib/python2.7/dist-packages/apache_beam/io/gcp/gcsio.py:113: DeprecationWarning: object() takes no parameters\n",
      "  super(GcsIO, cls).__new__(cls, storage_client))\n",
      "/usr/local/lib/python2.7/dist-packages/apache_beam/coders/typecoders.py:135: UserWarning: Using fallback coder for typehint: Any.\n",
      "  warnings.warn('Using fallback coder for typehint: %r.' % typehint)\n",
      "\u001b[31mDEPRECATION: pip install --download has been deprecated and will be removed in the future. Pip now has a download command that should be used instead.\u001b[0m\n",
      "Collecting google-cloud-dataflow==2.0.0\n",
      "  Downloading google-cloud-dataflow-2.0.0.tar.gz (576kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 1.7MB/s \n",
      "\u001b[?25h  Saved /tmp/tmpB1fDK8/google-cloud-dataflow-2.0.0.tar.gz\n",
      "Successfully downloaded google-cloud-dataflow\n"
     ]
    }
   ],
   "source": [
    "!python trainer/preprocess.py \\\n",
    "  --input_dict $GCS_BUCKET/img/flower_photos/dict.txt \\\n",
    "  --input_path $GCS_BUCKET/img/flower_photos/train_set.csv \\\n",
    "  --output_path $GCS_PATH/preproc/train \\\n",
    "  --num_workers 10 \\\n",
    "  --cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocessed Images: Simple copy tfrecords below (Avoid 50 min. Processing time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://lytx-experiment/1512512700/preproc/* $GCS_PATH/preproc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training\n",
    "Once we've preprocessed data, we can then train a simple classifier. The network will comprise a single fully-connected layer with RELU activations and with one output for each label in the dictionary to replace the original output layer. Final output is computed using the softmax function\n",
    "\n",
    "\n",
    "![Training](incept_v3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo $GCS_PATH\n",
    "echo $GCS_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "JOBNAME=lytx_$(date -u +%y%m%d_%H%M%S)\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --stream-logs \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=./trainer \\\n",
    "  --staging-bucket=$GCS_BUCKET \\\n",
    "  --region=us-central1 \\\n",
    "  --runtime-version=1.0 \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  -- \\\n",
    "  --output_path=$GCS_PATH/$JOBNAME/output \\\n",
    "  --eval_data_paths=$GCS_PATH/preproc/eval* \\\n",
    "  --train_data_paths=$GCS_PATH/preproc/train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $JOBNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## TensorBoard - View our Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('gs://lytx-dry-run/1513014343/lytx_171211_182542/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"lytx_dry_run\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=\"gs://lytx-dry-run/1513014343/lytx_171211_182542/output/model\" #REPLACE this with the location of your model\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions us-central1\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://cloud-ml-data/img/flower_photos/daisy/100080576_f52e8ee070_n.jpg daisy.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -c 'import base64, sys, json; img = base64.b64encode(open(sys.argv[1], \"rb\").read()); print json.dumps({\"key\":\"0\", \"image_bytes\": {\"b64\": img}})' daisy.jpg &> request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine predict --model lytx_prep --json-instances request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil cat $GCS_BUCKET/img/flower_photos/dict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://www.heirloomroses.com/media/catalog/product/cache/1/image/650x/040ec09b1e35df139433887a97daa66f/g/r/gr842-love-1_1.jpg\n",
    "mv gr842-love-1_1.jpg rose.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -c 'import base64, sys, json; img = base64.b64encode(open(sys.argv[1], \"rb\").read()); print json.dumps({\"key\":\"1\", \"image_bytes\": {\"b64\": img}})' rose.jpg &>> request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine predict --model lytx_prep --json-instances request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
