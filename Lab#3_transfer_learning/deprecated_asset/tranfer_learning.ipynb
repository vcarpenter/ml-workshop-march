{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classify Images via [Transfer Learning](https://en.wikipedia.org/wiki/Transfer_learning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<font color=\"red\"><b>This is NOT an Official Google Product and is only for education!!!</b></font>\n",
    "<br><br>\n",
    "[Google Cloud Vision API](https://cloud.google.com/vision/) is a popular service that allows users to classify images into categories, appropriate for multiple common use cases across several industries. For those users whose category requirements map to the pre-built, pre-trained machine-learning model reflected in the API, this approach is ideal. However, other users have more specialized requirements â€” for example, to identify specific products and soft goods in mobile-phone photos, or to detect nuanced differences between particular animal species in wildlife photography. For them, it can be more efficient to train and serve a new image model using [Google Cloud Machine Learning](https://cloud.google.com/products/machine-learning/) (Cloud ML), the managed service for building and running machine-learning models at scale using the open source [TensorFlow](https://www.tensorflow.org/) deep-learning framework.\n",
    "\n",
    "The goal of this lab is to build a simple tensorflow model via [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) in Cloud ML to identify the flower type:  daisy, dandelion, roses, sunflowers and tulips using a small set of labeled flower images. This dataset has been selected for ease of explanation only; We've successfully used the same implementation for several proprietary datasets covering cases like interior-design classification (e.g., carpet vs. hardwood floor) and animated-character classification. This code can easily be adapted to run on different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Set Up Environment\n",
    "Lets get our environment set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "PROJECT = os.popen(\"gcloud config list --format 'value(core.project)' 2>/dev/null\").read().rstrip('\\n')\n",
    "AUTH_NAME = os.popen(\"gcloud auth list --filter=status:ACTIVE --format='value(account)'\").read().split('@')[0].rstrip('\\n')\n",
    "REGION = 'us-central1'\n",
    "TIME = str(int(time.time()))\n",
    "GCS_BUCKET = 'gs://ml-workshop-transfer-learning-' + TIME + '-' + AUTH_NAME\n",
    "GCS_PATH = GCS_BUCKET + \"/\" + TIME\n",
    "JOBNAME = 'ml_workshop_' + TIME\n",
    "\n",
    "# Set Env Variables\n",
    "os.environ['GCS_BUCKET'] = GCS_BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['GCS_PATH'] = GCS_PATH\n",
    "os.environ['JOBNAME'] = JOBNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prepare data\n",
    "gs://cloud-ml-data is a public storage bucket on [Google Cloud Storage](https://cloud.google.com/storage/) that hosts our training and test data for transfer learning excercise. We will keep the actual images of flowers in gs://cloud-ml-data and instead copy only the labelled csv files for training and evaluation. Codeblock below creates a bucket and copies the labelled csv dataset from  gs://cloud-ml-data to our bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil mb $GCS_BUCKET\n",
    "!gsutil cp -r gs://cloud-ml-data/img/flower_photos/train_set.csv $GCS_BUCKET/img/flower_photos/\n",
    "!gsutil cp -r gs://cloud-ml-data/img/flower_photos/eval_set.csv $GCS_BUCKET/img/flower_photos/\n",
    "!gsutil cp -r gs://cloud-ml-data/img/flower_photos/dict.txt $GCS_BUCKET/img/flower_photos/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Understand our Data\n",
    "Both train_set.csv and eval_set.csv have labelled dataset in the following format. We will use this labelled dataset to teach our model things like what a sunflower, rose, tulip, daisy and dandelion look like\n",
    "<pre>\n",
    "gs://cloud-ml-data/img/flower_photos/dandelion/17388674711_6dca8a2e8b_n.jpg,dandelion\n",
    "gs://cloud-ml-data/img/flower_photos/sunflowers/9555824387_32b151e9b0_m.jpg,sunflowers\n",
    "gs://cloud-ml-data/img/flower_photos/daisy/14523675369_97c31d0b5b.jpg,daisy\n",
    "gs://cloud-ml-data/img/flower_photos/roses/512578026_f6e6f2ad26.jpg,roses\n",
    "gs://cloud-ml-data/img/flower_photos/tulips/497305666_b5d4348826_n.jpg,tulips...\n",
    "</pre>\n",
    "We also need a text file containing all the labels (dict.txt), which is used to sequentially map labels to internally used IDs. In this case, daisy would become ID 0 and tulips would become 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil cat -r 0-85  $GCS_BUCKET/img/flower_photos/eval_set.csv\n",
    "!gsutil cat $GCS_BUCKET/img/flower_photos/dict.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training Data vs. Test Data\n",
    "We have randomly split data into two files, train_set.csv and eval_set.csv, with 90% data for training and 10% for eval, respectively. Read more on training vs. test [here](https://en.wikipedia.org/wiki/Training,_test,_and_validation_sets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil cat $GCS_BUCKET/img/flower_photos/train_set.csv | wc -l\n",
    "!gsutil cat $GCS_BUCKET/img/flower_photos/eval_set.csv | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocess Data\n",
    "We start with a set of labeled images in a Google Cloud Storage bucket and preprocess them to extract the image features from the bottleneck layer (typically the penultimate layer) of the Inception network. Although processing images in this manner can be reasonably expensive, each image can be processed independently and in parallel, making this task a great candidate for [Cloud Dataflow](https://cloud.google.com/dataflow/).\n",
    "\n",
    "We process each image to produce its feature representation (also known as an embedding) in the form of a k-dimensional vector of floats (in our case 2,048 dimensions). The preprocessing includes converting the image format, resizing images, and running the converted image through a pre-trained model to get the embeddings. Final output will be written in directory specified by --output_path.\n",
    "\n",
    "To measure the benefit of parallelizing preprocessing on Google Cloud, we ran the above preprocessing on 1 million sample images from the Open Image Dataset. We found that while it takes several days to preprocess 1 million images locally, it takes less than 2 hours on the cloud when we use 100 workers with four cores each!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Machine Learning Pipeline \n",
    "<p align='left'>We are setting up following pipeline </p>\n",
    "\n",
    "<img src='./images_for_markdown/pipeline.png' width=1000 align=left></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br>\n",
    "### How to run Preprocessing Job \n",
    "(uri, label_ids, embedding) -> (tensorflow.Example) (Many tensorflow.Example make 1 TfRecord)\n",
    "\n",
    "  Output proto contains 'label', 'image_uri' and 'embedding'.\n",
    "  The 'embedding' is calculated by feeding image into input layer of image\n",
    "  neural network and reading output of the bottleneck layer of the network.\n",
    "\n",
    "  Below gives you an example of how you would run this at scale for all the flower images we have. \n",
    "  <pre>\n",
    "  !python trainer/preprocess.py \\\n",
    "  --input_dict $GCS_BUCKET/img/flower_photos/dict.txt \\\n",
    "  --input_path $GCS_BUCKET/img/flower_photos/eval_set.csv \\\n",
    "  --output_path $GCS_PATH/preproc/eval \\\n",
    "  --num_workers 10 \\\n",
    "  --cloud\n",
    "  </pre>\n",
    "  \n",
    "  <pre>\n",
    "  !python trainer/preprocess.py \\\n",
    "  --input_dict $GCS_BUCKET/img/flower_photos/dict.txt \\\n",
    "  --input_path $GCS_BUCKET/img/flower_photos/train_set.csv \\\n",
    "  --output_path $GCS_PATH/preproc/train \\\n",
    "  --num_workers 10 \\\n",
    "  --cloud\n",
    "  </pre>\n",
    "  \n",
    "  But today we wont run it to save cost and time. Instead we will run a much smaller job just to get a feel for it. Go ahead & run the following job & check the job status [here](https://console.cloud.google.com/dataflow?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil cp dataflow_slim.csv $GCS_PATH/slim_job/input/dataflow_slim.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!python trainer/preprocess_fast.py \\\n",
    "  --input_dict $GCS_BUCKET/img/flower_photos/dict.txt \\\n",
    "  --input_path $GCS_PATH/slim_job/input/dataflow_slim.csv \\\n",
    "  --output_path $GCS_PATH/slim_job/output \\\n",
    "  --cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocessed Images: Simple copy tfrecords below (Avoid 50 min. Processing time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil -m cp gs://lytx-experiment/1512512700/preproc/* $GCS_PATH/preproc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training\n",
    "Once we've preprocessed data, we can then train a simple classifier. The network will comprise a single fully-connected layer with RELU activations and with one output for each label in the dictionary to replace the original output layer. Final output is computed using the softmax function\n",
    "<br><br>\n",
    "<img src='./images_for_markdown/incept_v3.png' align='center' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Launch a Training Job\n",
    "Below we will launch a remore distributed training job on Cloud Machine Learning Engine (Cloud ML). To learn more on how to run the job please visit this [link](https://cloud.google.com/ml-engine/docs/training-overview) Please check your job status [here](https://console.cloud.google.com/mlengine/jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --stream-logs \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=./trainer \\\n",
    "  --staging-bucket=$GCS_BUCKET \\\n",
    "  --region=us-central1 \\\n",
    "  --runtime-version=1.0 \\\n",
    "  --scale-tier=BASIC \\\n",
    "  -- \\\n",
    "  --output_path=$GCS_PATH/$JOBNAME/output \\\n",
    "  --eval_data_paths=$GCS_PATH/preproc/eval* \\\n",
    "  --train_data_paths=$GCS_PATH/preproc/train*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## TensorBoard - View our Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TENSORBOARD_PATH = GCS_PATH + \"/\" + JOBNAME + \"/output\"\n",
    "print (TENSORBOARD_PATH)\n",
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start(TENSORBOARD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run an Inference Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"ml_workshop\"\n",
    "MODEL_VERSION=\"v2\"\n",
    "\n",
    "#ADD YOUR MODEL PATH Below. EXPLORE CLOUD STORAGE BUCKET TO SEE WHERE THE MODEL IS CREATED. HINT $GCS_PATH/$JOBNAME/output/model \n",
    "MODEL_LOCATION='gs://ml-workshop-transfer-learning-1522282044-155051428461-compute/1522282044/ml_workshop_1522282044/output/model' \n",
    "#ADD YOUR MODEL PATH ABOVE. EXPLORE CLOUD STORAGE BUCKET FOR THE SAME \n",
    "\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions us-central1\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -c 'import base64, sys, json; img = base64.b64encode(open(sys.argv[1], \"rb\").read()); print json.dumps({\"key\":\"0\", \"image_bytes\": {\"b64\": img}})' ./test_images/daisy.jpg &> request.json\n",
    "python -c 'import base64, sys, json; img = base64.b64encode(open(sys.argv[1], \"rb\").read()); print json.dumps({\"key\":\"1\", \"image_bytes\": {\"b64\": img}})' ./test_images/rose.jpg &>> request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ml-engine predict --model $MODEL_NAME --json-instances request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!gsutil cat $GCS_BUCKET/img/flower_photos/dict.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
